# Сумма ряда

## предварительная версия

Представляет из себя 3 варианта программы, суммирующей ряд из задания. Мой вариант 6.

### Изменение под себя

Исходный код лежит в файлах `onethread/main.c`, `openMP/main.c`, `mpi/main.c`. Чтобы изменить считаемый ряд, необходимов в каждом из этих файлов найти и изменить функцию `f(unsigned long long int k)`.

## Запуск.

Нормально все варианты можно запустить только под линукс, но при должном уровне сноровки, можно и под виндой погонять

1. Однопоточная программа

	$ gcc -std="c99" -Wall -pedantic -o main onethread/main.c -lm && ./main 1000000

Расчёт и суммирование миллиона членов ряда.
 
2. Сборка однопоточной программы с помощью компилятора intel

	$ icc -std="c99" -Wall -pedantic -o main onethread/main.c -lm && ./main 1000000

3. Запустить первые 2 расчёта с 2 и 3 миллионами элементов
4. Запустить первые 2 расчёта с флагом `-ffast-math` вместо флага `-lm`, а также с 2 и 3 миллионами элементов
5. После флага `-pedantic` выставить флаги оптимизации `-O1`, `-O2`, `-O3` и для icc также флаг `-fast`, а для gcc флаг `-lrt` (по желанию).
Провести все расчёты выше для каждого из этих флагов. Пример

	$ icc -std="c99" -Wall -pedantic -O2 -o main onethread/main.c -lm && ./main 1000000

Флаг `-lrt` (left -> right -> tree) можно комбинаровать с другими флагами, Пример

	$ gcc -std="c99" -Wall -pedantic -lrt -O3 -o main onethread/main.c -lm && ./main 1000000

6. Автоматичесоке распараллеливание
Не секрет, что программу можно ускорить, если итерации цикла будут выполняться на разных ядрах/потоках И так далее, короче все одновременно.
Компилятору icc можно подсказать, тогда он сделает цикл параллельным.

	$ icc -std="c99" -Wall -pedantic -O3 -o main onethread/main.c -lm -qpo -ipo -restrict -guide-par -parallel -par-threshold -par-report3 -vec-report3 && ./main 1000000
	
Вообще говоря, команда выше делает много чего лишнего, возможно, хватит только флага `-parallel`.
Флаги `-par-report3` и `-vec-report3` выводят на экран информацию о том, что именно и как было распараллелено.

Провести вычисления также со всеми флагами оптимизации и 2 и 3 миллионами
 
7. openMP
OpenMP - технология подсказок компилятору прямо в исходном коде программы
В нашем случае это специальная #pragma перед циклом. Исходный код лежит в папке openMP
Компиляторам тоже надо сказать, чтобы эти прагмы не игногрировались с помощью специального флага

	$ gcc -std="c99" -Wall -pedantic -lrt -O3 -o main openMP/main.c -lm -fopenmp && ./main 1000000
	$ icc -std="c99" -Wall -pedantic -fast` -o main openMP/main.c -lm -openmp && ./main 1000000

Провести вычисления со всеми флагами оптимизации

8. MPI
технология написания параллельных программ для систем с распределённой памятью, таких как суперкомпютер
Требуется очень серьёзная переделка кода из обычной программы в MPIшную. Он в папке `mpi`.

Компиляция с помошью mpicc, впрочем, можно указать использование любого стороннего компилятора с помошью флага `-cc`, напрммер `mpicc -cc="icc"`
Запуск с помошью `mpirun`, флаг `-np` позволяет указать количество процессов для запуска программы. Желательно, число равное количеству процессоров.

	mpicc -std="c99" -Wall -pedantic -o main mpi/main.c -lm && mpirun -np 17 ./main 1000000
	mpicc -std="c99" -cc="icc" -Wall -pedantic -o main mpi/main.c -lm && mpirun -np 17 ./main 1000000
	
Провести вычисления со всеми оптимизациями.

9. Запуск MPI программы на суперкомпе

Настраиваем подключение к суперкомпютеру, и переносим туда файлы

### Отчёт
Набросок отчёта - файл report.tex, но я его только начал.
report.pdf можно почитать и посмотреть
