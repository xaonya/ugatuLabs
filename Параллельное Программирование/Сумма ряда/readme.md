# Сумма ряда
## Вариант 6

Представляет из себя 3 варианта программы, суммирующей ряд из задания.

## Изменение под себя

Исходный код лежит в файлах `onethread/main.c`, `openMP/main.c`, `mpi/main.c`. Чтобы изменить считаемый ряд, необходимов в каждом из этих файлов найти и изменить функцию `f(unsigned long long int k)`.

## Запуск.

Нормально все варианты можно запустить только под линукс, но при должном уровне сноровки, можно и под виндой погонять

### Однопоточная программа

    $ gcc -std="c99" -Wall -pedantic -o main onethread/main.c -lm && ./main 1000000

* Расчёт и суммирование миллиона, а также двух и трёх миллионов членов ряда.
* После флага `-pedantic` выставить флаги оптимизации `-O1`, `-O2`, `-O3` и провести расчёты с одним, двумя и тремя миллионами элементов ряда
* По желанию, провести расчёты также с использованием флага `-lrt`

Флаг `-lrt` (left -> right -> tree) можно комбинаровать с другими флагами, Пример

    $ gcc -std="c99" -Wall -pedantic -lrt -O3 -o main onethread/main.c -lm && ./main 1000000

### Сборка однопоточной программы с помощью компилятора intel

    $ icc -std="c99" -Wall -pedantic -o main onethread/main.c -lm && ./main 1000000

* Расчёт и суммирование миллиона, а также двух и трёх миллионов членов ряда.
* Провести расчёт с использованием флага `-ffast-math` вместо флага `-lm`
* После флага `-pedantic` выставить флаги оптимизации `-O1`, `-O2`, `-O3`, а также флаг `-fast` и провести расчёты с одним, двумя и тремя миллионами элементов ряда

Пример

    $ icc -std="c99" -Wall -pedantic -O2 -o main onethread/main.c -lm && ./main 1000000

### Автоматичесоке распараллеливание
Не секрет, что программу можно ускорить, если не связанные итерации цикла будут выполняться на разных ядрах/потоках

Компилятору icc можно подсказать что итерации циклом между собой не связаны, и тогда он сделает цикл параллельным

    $ icc -std="c99" -Wall -pedantic -O3 -o main onethread/main.c -lm -qpo -ipo -restrict -guide-par -parallel -par-threshold -par-report3 -vec-report3 && ./main 1000000
	
Вообще говоря, команда выше делает много чего лишнего, возможно, хватит только флага `-parallel`.

Флаги `-par-report3` и `-vec-report3` выводят на экран информацию о том, что именно и как было распараллелено.

Необходимо провести вычисления также со всеми флагами оптимизации и 2 и 3 миллионами
 
### OpenMP
OpenMP - технология подсказок компилятору прямо в исходном коде программы

В нашем случае это специальная директива `#pragma` перед циклом. Исходный код лежит в папке `openMP`

Компиляторам тоже надо сказать, чтобы эти прагмы не игногрировались с помощью специального флага

    $ gcc -std="c99" -Wall -pedantic -lrt -o main openMP/main.c -lm -fopenmp && ./main 1000000
    $ icc -std="c99" -Wall -pedantic -o main openMP/main.c -lm -openmp && ./main 1000000

Провести вычисления со всеми флагами оптимизации

### MPI
технология написания параллельных программ для систем с распределённой памятью, таких как суперкомпютер
Требуется очень серьёзная переделка кода из обычной программы в MPIшную. Он в папке `mpi`.

Компиляция с помошью `mpicc`, впрочем, можно указать использование любого стороннего компилятора с помошью флага `-cc`, напрммер `mpicc -cc="icc"`
Запуск с помошью `mpirun`, флаг `-np` позволяет указать количество процессов для запуска программы. Желательно, число равное количеству процессоров.

    $ mpicc -std="c99" -Wall -pedantic -o main mpi/main.c -lm && mpirun -np 17 ./main 1000000
    $ mpicc -std="c99" -cc="icc" -Wall -pedantic -o main mpi/main.c -lm && mpirun -np 17 ./main 1000000
	
Провести вычисления со всеми оптимизациями.

### Запуск MPI программы на суперкомпьютере (Вычислительном кластере УГАТУ)

Настраиваем подключение к суперкомпьютеру, и переносим туда файлы

Для запуска редактируем файлы `job1.pbs` и `job2.pbs`

## Отчёт
Набросок отчёта - файл `report.tex`, но я его только начал.

`report.pdf` можно почитать и посмотреть
